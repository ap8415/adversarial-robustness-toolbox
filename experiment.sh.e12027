2019-06-05 14:21:21.483455: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-06-05 14:21:21.492533: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3691870000 Hz
2019-06-05 14:21:21.493039: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a42165d2e0 executing computations on platform Host. Devices:
2019-06-05 14:21:21.493078: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-05 14:21:21.697202: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a42083d3e0 executing computations on platform CUDA. Devices:
2019-06-05 14:21:21.697247: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX TITAN X, Compute Capability 5.2
2019-06-05 14:21:21.697942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:03:00.0
totalMemory: 11.93GiB freeMemory: 11.70GiB
2019-06-05 14:21:21.697977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-06-05 14:21:21.699485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-05 14:21:21.699514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-06-05 14:21:21.699527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-06-05 14:21:21.699991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11385 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
2019-06-05 14:21:21.776408: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 11.12G (11938761728 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.785590: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 10.01G (10744885248 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.792627: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 9.01G (9670396928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.799802: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 8.11G (8703356928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.806720: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 7.29G (7833020928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.813645: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 6.57G (7049718784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.820693: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.91G (6344746496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.827673: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.32G (5710271488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.834645: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 4.79G (5139244032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.841607: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 4.31G (4625319424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.848668: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 3.88G (4162787328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.855559: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 3.49G (3746508544 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.862443: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 3.14G (3371857664 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.869405: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 2.83G (3034671872 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.876338: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 2.54G (2731204608 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.883421: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 2.29G (2458084096 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.890357: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 2.06G (2212275712 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.897233: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.85G (1991048192 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.904219: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.67G (1791943424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.911020: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.50G (1612749056 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.917724: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.35G (1451474176 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.924463: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.22G (1306326784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.931579: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1.09G (1175694080 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.938406: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 1009.11M (1058124800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.945390: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 908.20M (952312320 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.952146: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 817.38M (857081088 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.959156: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 735.64M (771373056 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.965992: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 662.07M (694235904 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.972826: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 595.87M (624812288 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:21.979767: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 536.28M (562331136 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-06-05 14:21:23.667885: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.9.0 locally
2019-06-05 14:21:23.730042: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.743132: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.751175: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.760070: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.767668: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.775557: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.783151: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.790987: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.855389: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2019-06-05 14:21:23.855444: W tensorflow/stream_executor/stream.cc:2130] attempting to perform BLAS operation using StreamExecutor without BLAS support
Using TensorFlow backend.
Traceback (most recent call last):
  File "experiments/transferability/three_layer_dnn.py", line 38, in <module>
    dropout_classifier.fit(x_train, y_train, nb_epochs=10, batch_size=128)
  File "/vol/gpudata/ap8415/adversarial-robustness-toolbox/art/classifiers/keras.py", line 312, in fit
    **kwargs)
  File "/vol/gpudata/ap8415/miniconda3/envs/venv/lib/python3.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/vol/gpudata/ap8415/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File "/vol/gpudata/ap8415/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training_generator.py", line 217, in fit_generator
    class_weight=class_weight)
  File "/vol/gpudata/ap8415/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 1217, in train_on_batch
    outputs = self.train_function(ins)
  File "/vol/gpudata/ap8415/miniconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    return self._call(inputs)
  File "/vol/gpudata/ap8415/miniconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File "/vol/gpudata/ap8415/miniconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1439, in __call__
    run_metadata_ptr)
  File "/vol/gpudata/ap8415/miniconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(128, 784), b.shape=(784, 300), m=128, n=300, k=784
	 [[{{node dense_1/MatMul}}]]
	 [[{{node metrics/acc/Mean}}]]
